{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/kurian/code/python/kaggle/kaggle/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making model\n",
    "model=Sequential()\n",
    "inputShape=(28,28,1)\n",
    "#Conv2D did not accept(784,-1),(784,testcases) as an input shape\n",
    "model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=inputShape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21001 samples, validate on 21000 samples\n",
      "Epoch 1/12\n",
      "21001/21001 [==============================] - 13s 621us/step - loss: 8.2134 - acc: 0.4804 - val_loss: 6.5661 - val_acc: 0.5868\n",
      "Epoch 2/12\n",
      "21001/21001 [==============================] - 13s 609us/step - loss: 6.5735 - acc: 0.5867 - val_loss: 6.5947 - val_acc: 0.5850\n",
      "Epoch 3/12\n",
      "21001/21001 [==============================] - 13s 599us/step - loss: 6.4393 - acc: 0.5965 - val_loss: 6.3752 - val_acc: 0.6004\n",
      "Epoch 4/12\n",
      "21001/21001 [==============================] - 13s 597us/step - loss: 4.2330 - acc: 0.7204 - val_loss: 2.2398 - val_acc: 0.8314\n",
      "Epoch 5/12\n",
      "21001/21001 [==============================] - 12s 595us/step - loss: 0.8888 - acc: 0.9206 - val_loss: 0.2931 - val_acc: 0.9582\n",
      "Epoch 6/12\n",
      "21001/21001 [==============================] - 13s 597us/step - loss: 0.1738 - acc: 0.9700 - val_loss: 0.1928 - val_acc: 0.9658\n",
      "Epoch 7/12\n",
      "21001/21001 [==============================] - 13s 598us/step - loss: 0.0964 - acc: 0.9811 - val_loss: 0.1722 - val_acc: 0.9678\n",
      "Epoch 8/12\n",
      "21001/21001 [==============================] - 13s 608us/step - loss: 0.0597 - acc: 0.9863 - val_loss: 0.1995 - val_acc: 0.9618\n",
      "Epoch 9/12\n",
      "21001/21001 [==============================] - 13s 616us/step - loss: 0.0360 - acc: 0.9917 - val_loss: 0.1652 - val_acc: 0.9698\n",
      "Epoch 10/12\n",
      "21001/21001 [==============================] - 13s 608us/step - loss: 0.0251 - acc: 0.9950 - val_loss: 0.1778 - val_acc: 0.9689\n",
      "Epoch 11/12\n",
      "21001/21001 [==============================] - 13s 605us/step - loss: 0.0184 - acc: 0.9967 - val_loss: 0.1530 - val_acc: 0.9732\n",
      "Epoch 12/12\n",
      "21001/21001 [==============================] - 13s 605us/step - loss: 0.0128 - acc: 0.9980 - val_loss: 0.1618 - val_acc: 0.9741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x127fcbf98>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making dataloader,\n",
    "# this was mainly to convert pandas dataframe to numpy array\n",
    "# keras inbuilt functionality and reshape functionality are\n",
    "# available for numpy.\n",
    "\n",
    "import pandas as pd\n",
    "def MnistLoadData(X,Y):\n",
    "    lenx=len(X)\n",
    "    lenY=len(Y)\n",
    "    #splitting input data to test and train\n",
    "    x1=X.loc[0:lenx/2]\n",
    "    x2=X.loc[lenx/2:lenx]\n",
    "    y1=Y.loc[0:lenY/2]\n",
    "    y2=Y.loc[lenY/2:lenY]\n",
    "    #converting pandas datafram to numpy\n",
    "    #for performing reshape and using \n",
    "    #to_categorical functions of keras\n",
    "    x1=x1.to_numpy()\n",
    "    x2=x2.to_numpy()\n",
    "    y1=y1.to_numpy()\n",
    "    y2=y2.to_numpy()\n",
    "    x1=x1.reshape(x1.shape[0],28,28,1)\n",
    "    x2=x2.reshape(x2.shape[0],28,28,1)\n",
    "    #one hot encoding functionality of keras\n",
    "    #converts y to its corresponding probablity array\n",
    "    #1=[1,0,0,0,0,0,0,0...]\n",
    "    #2=[0,1,0,0,0,0,0,....]\n",
    "    y1=keras.utils.to_categorical(y1,10)\n",
    "    y2=keras.utils.to_categorical(y2,10)\n",
    "    return (x1,y1),(x2,y2)\n",
    "\n",
    "#reading dataset\n",
    "dataset=pd.read_csv('dataset/digit-recognizer/train.csv')\n",
    "X=dataset.drop('label',axis=1)\n",
    "Y=dataset['label']\n",
    "\n",
    "#loading data\n",
    "(x1,y1),(x2,y2)=MnistLoadData(X,Y)\n",
    "#making model, here neural net extracts characteristic weights for this dataset\n",
    "#so that it can make predictions\n",
    "model.fit(x1,y1,batch_size=128,epochs=12,verbose=1,validation_data=(x2,y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000/21000 [==============================] - 4s 193us/step\n"
     ]
    }
   ],
   "source": [
    "#check using the second half of the dataset, how accurate the prediction is\n",
    "model.evaluate(x2,y2,verbose=1)\n",
    "\n",
    "#loading data from csv for predictions\n",
    "#xtest need not be seperated since it only has input vector\n",
    "Xtest=pd.read_csv('dataset/digit-recognizer/test.csv')\n",
    "Xtest=Xtest.to_numpy()\n",
    "Xtest=Xtest.reshape(Xtest.shape[0],28,28,1)\n",
    "Ytest=model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the submission file\n",
    "from numpy import argmax\n",
    "import numpy as np\n",
    "Yarray=[]\n",
    "i=1\n",
    "for nu in Ytest:\n",
    "    Yarray.append((i,int(argmax(nu))))\n",
    "    i=i+1\n",
    "\n",
    "np.savetxt(\"dataset/digit-recognizer/submission.csv\",np.asarray(Yarray),delimiter=\",\",fmt=\"%d\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
